{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User1\\anaconda3\\envs\\Environment4\\Lib\\site-packages\\keras\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "File \u001b[1;32mc:\\Users\\User1\\anaconda3\\envs\\Environment4\\Lib\\site-packages\\keras\\activations\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m elu\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exponential\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gelu\n",
      "File \u001b[1;32mc:\\Users\\User1\\anaconda3\\envs\\Environment4\\Lib\\site-packages\\keras\\activations\\activations.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n",
      "File \u001b[1;32mc:\\Users\\User1\\anaconda3\\envs\\Environment4\\Lib\\site-packages\\keras\\backend\\__init__.py:33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Import backend functions.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjax\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User1\\anaconda3\\envs\\Environment4\\Lib\\site-packages\\keras\\backend\\tensorflow\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribution_lib\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n",
      "File \u001b[1;32mc:\\Users\\User1\\anaconda3\\envs\\Environment4\\Lib\\site-packages\\keras\\backend\\tensorflow\\core.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf2xla\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxla\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dynamic_update_slice\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasVariable\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scienceplots\n",
    "import shap\n",
    "\n",
    "import events_package.utils as utils\n",
    "from events_package.Experiment import Experiment\n",
    "from events_package.config import FIVE_LAYERS\n",
    "from events_package.input_getters import get_Y_1, get_X_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiment.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing Single Particle Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Electrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444840"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing data\n",
    "dataset_df = pd.read_parquet(\n",
    "    r\"C:\\Users\\User1\\Desktop\\MSci_Project\\Data\\6_data\\Electron\\Parquet\\1m_electron_pq_3\"\n",
    ")\n",
    "\n",
    "electrons = Experiment(dataset_df, config=FIVE_LAYERS)\n",
    "del dataset_df\n",
    "electrons.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Removed duplicates\n",
      "INFO: Denoisified the dataset\n",
      "INFO: Shuffled dataset\n",
      "INFO: Number of events after removing duplicates: 434998\n",
      "INFO: Removed events with 0 energy in layers after denoisifying\n",
      "INFO: Number of events after removing 0 energy (in calorimeters) events: 434998\n"
     ]
    }
   ],
   "source": [
    "electrons.standard_procedure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Photons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444142"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = pd.read_parquet(\n",
    "    r\"C:\\Users\\User1\\Desktop\\MSci_Project\\Data\\6_data\\Photon\\Parquet\\1m_photon_pq\"\n",
    ")\n",
    "\n",
    "photons = Experiment(dataset_df, config=FIVE_LAYERS)\n",
    "del dataset_df\n",
    "photons.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Removed duplicates\n",
      "INFO: Denoisified the dataset\n",
      "INFO: Shuffled dataset\n",
      "INFO: Number of events after removing duplicates: 434870\n",
      "INFO: Removed events with 0 energy in layers after denoisifying\n",
      "INFO: Number of events after removing 0 energy (in calorimeters) events: 434870\n"
     ]
    }
   ],
   "source": [
    "photons.standard_procedure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Neutral Pions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412856"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = pd.read_parquet(\n",
    "    r\"C:\\Users\\User1\\Desktop\\MSci_Project\\Data\\6_data\\PiZero\\Parquet\\pq_pi0_2\"\n",
    ")\n",
    "\n",
    "pi0 = Experiment(dataset_df, config=FIVE_LAYERS)\n",
    "del dataset_df\n",
    "pi0.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Removed duplicates\n",
      "INFO: Denoisified the dataset\n",
      "INFO: Shuffled dataset\n",
      "INFO: Number of events after removing duplicates: 391483\n",
      "INFO: Removed events with 0 energy in layers after denoisifying\n",
      "INFO: Number of events after removing 0 energy (in calorimeters) events: 391483\n"
     ]
    }
   ],
   "source": [
    "pi0.standard_procedure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Charged Pions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357554"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = pd.read_parquet(\n",
    "    r\"C:\\Users\\User1\\Desktop\\MSci_Project\\Data\\6_data\\PiPlusMinus\\Parquet\\pq_piplusminus_2\"\n",
    ")\n",
    "\n",
    "pi_char = Experiment(dataset_df, config=FIVE_LAYERS)\n",
    "del dataset_df\n",
    "pi_char.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Removed duplicates\n",
      "INFO: Denoisified the dataset\n",
      "INFO: Shuffled dataset\n",
      "INFO: Number of events after removing duplicates: 330809\n",
      "INFO: Removed events with 0 energy in layers after denoisifying\n",
      "INFO: Number of events after removing 0 energy (in calorimeters) events: 330803\n"
     ]
    }
   ],
   "source": [
    "pi_char.standard_procedure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dense Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add types to allow for identification later\n",
    "electrons.add_physics_object_type(typ=\"electron\")\n",
    "photons.add_physics_object_type(typ=\"photon\")\n",
    "pi0.add_physics_object_type(typ=\"pi0\")\n",
    "pi_char.add_physics_object_type(typ=\"pi_char\")\n",
    "\n",
    "experiment = electrons + photons + pi0 + pi_char\n",
    "\n",
    "# all previous datasets have already been denoisified, duplicates were removed, no need to do it now\n",
    "# in fact, doing it would delete some good events\n",
    "experiment.shuffle_dataset(repeats=11)\n",
    "print(experiment.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.train_test_split(get_X=get_X_5, get_Y=get_Y_1, test_size=0.2)\n",
    "experiment.X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = experiment.X_train\n",
    "Y_train = experiment.y_train\n",
    "X_test = experiment.X_test\n",
    "Y_test = experiment.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dense(120, input_shape=X_train[0].shape, activation=\"relu\"))\n",
    "\n",
    "# dense layers\n",
    "model.add(keras.layers.Dense(80, activation=\"relu\"))  # dense layer, 256 nodes\n",
    "model.add(keras.layers.Dense(40, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(28, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(4, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(1))  # 1 outout as we want to have z\n",
    "\n",
    "model.compile(\n",
    "    loss=\"mean_squared_error\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"mse\"],\n",
    ")\n",
    "\n",
    "# print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history = model.fit(\n",
    "    X_train, Y_train, validation_data=(X_test, Y_test), epochs=35, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"mse\"], label=\"Training MSE\")\n",
    "plt.plot(history.history[\"val_mse\"], label=\"Validation MSE\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.grid()\n",
    "plt.title(\"Model Training Metrics over Epochs\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "Y_pred = Y_pred.reshape(\n",
    "    Y_pred.shape[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_predictions(Y_test, Y_pred)\n",
    "utils.plot_errors(Y_test, Y_pred, xmax=350, xcut=350, binnum=100)\n",
    "utils.plot_corelation(Y_test, Y_pred, density=True, log_density=False, plot_line=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    \"psb eta\",\n",
    "    \"emb1 eta\",\n",
    "    \"emb2 eta\",\n",
    "    \"emb3 eta\",\n",
    "    \"hab1 eta\",\n",
    "    \"psb - emb1 eta\",\n",
    "    \"emb1 - emb2 eta\",\n",
    "    \"emb2 - emb3 eta\",\n",
    "    \"emb3 - hab1 eta\",\n",
    "    \"psb(4)\",\n",
    "    \"psb(5) - psb(3)\",\n",
    "    \"emb1(8)\",\n",
    "    \"emb1(9) - emb1(7)\",\n",
    "    \"emb1(10) - emb1(6)\",\n",
    "    \"emb1(11) - emb1(5)\",\n",
    "    \"emb1(12) - emb1(4)\",\n",
    "    \"emb2(4)\",\n",
    "    \"emb2(5) - emb2(3)\",\n",
    "    \"emb3(4)\",\n",
    "    \"emb3(5) - emb3(3)\",\n",
    "    \"hab1(4)\",\n",
    "    \"hab1(5) - hab1(3)\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model, check_additivity=False)\n",
    "\n",
    "shap_values = explainer.shap_values(electrons.X_train, check_additivity=False)\n",
    "\n",
    "shap.summary_plot(shap_values, electrons.X_train, feature_names=feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
